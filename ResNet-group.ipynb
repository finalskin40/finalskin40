{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from ourtools import *\n",
    "from my_model.Basic_CNN import Basic_CNN\n",
    "from my_model.ADV_ResNet import *\n",
    "from torch.autograd import Variable\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import random\n",
    "\"\"\"\n",
    "tensorboard --logdir log\n",
    "\"\"\"\n",
    "base_path = os.getcwd()\n",
    "batch_size = 120\n",
    "input_size = 224  # 图片大小\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 3e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def init_model(multi_gpu = True):\n",
    "    \"\"\"\n",
    "    model = resnet152(pretrained=True) # Basic_CNN().to(device=DEVICE)\n",
    "    model.fc=nn.Linear(2048,40)\n",
    "    model = model.cuda()\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model,device_ids=[0,1,2])\n",
    "    \"\"\"\n",
    "    model = torch.load(\"pre-trained.pth\")\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=LEARNING_RATE,momentum=0.9,weight_decay=5e-4)\n",
    "    return model, optimizer\n",
    "\n",
    "print (\"Loading pretrained data\")\n",
    "model = resnet152(pretrained=True) # Basic_CNN().to(device=DEVICE)\n",
    "model.fc=nn.Linear(2048,40)\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model,device_ids=[0,1,2])\n",
    "# state_dict = torch.load('latest-ai.pth')\n",
    "# model.load_state_dict(state_dict)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=LEARNING_RATE,momentum=0.9,weight_decay=5e-4)\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.RandomCrop((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset = ImageFolder(\"Skin40\", transform=transform)\n",
    "print(dataset)\n",
    "print(dataset.class_to_idx)\n",
    "\n",
    "dataset1, dataset2, dataset3, dataset4, dataset5, testset = random_split(dataset, [400, 400, 400, 400, 400, 400])\n",
    "\n",
    "class trainer():\n",
    "    def __init__(self):\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.device = DEVICE\n",
    "        self.model = \"\"\n",
    "        self.optimizer = \"\"\n",
    "        \n",
    "    def print_confusion_matrix(self, y_pred,y_true):\n",
    "        sns.set()\n",
    "        f,ax = plt.subplots(figsize=(16,12))\n",
    "        C2 = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        recall_list=[]\n",
    "        for i in range(len(C2[0])):\n",
    "            aller = sum(C2[i])+1e-6\n",
    "            recall_list.append(C2[i][i]/aller)\n",
    "        \n",
    "        sns.heatmap(C2,annot=True,ax=ax,cmap=\"Blues\") #画热力图\n",
    "        ax.set_title('confusion matrix') #标题\n",
    "        ax.set_xlabel('predict') #x轴\n",
    "        ax.set_ylabel('true') #y轴\n",
    "        plt.show()\n",
    "        return sum(recall_list)/len(recall_list)\n",
    "\n",
    "    def evaluate(self, model_eval, loader_eval, criterion_eval):\n",
    "\n",
    "        model_eval.eval()\n",
    "        loss_eval = 0\n",
    "        correct = 0.0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in loader_eval:\n",
    "                data, target = Variable(data.cuda()),Variable(target.cuda())\n",
    "                output = self.model(data)\n",
    "                loss_eval += criterion_eval(output, target).item()\n",
    "\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "                for itm in pred:\n",
    "                    y_pred.append(int(itm))\n",
    "                for real in target:\n",
    "                    y_true.append(int(real))\n",
    "\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        baCC = self.print_confusion_matrix(y_pred,y_true)\n",
    "        loss_eval = loss_eval / loader_eval.dataset.__len__()\n",
    "        accuracy = correct / loader_eval.dataset.__len__()\n",
    "        response = {\"loss\": loss_eval, \"acc\": accuracy,\"bACC\":baCC}\n",
    "        return response\n",
    "    \n",
    "    def load_member(self, nid):\n",
    "        model = torch.load(\"latest-gp_ai_\"+str(nid)+\".pth\")\n",
    "        model.eval()\n",
    "        return model\n",
    "    \n",
    "    def test(self):\n",
    "        model_list = []\n",
    "        for i in range(0,5):\n",
    "            model_list.append(self.load_member(i))\n",
    "        \n",
    "        loader_eval = DataLoader(testset, shuffle=False, batch_size=batch_size)\n",
    "        loss_eval = 0.0\n",
    "        correct = 0.0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in loader_eval:\n",
    "                data, target = Variable(data.cuda()),Variable(target.cuda())\n",
    "                output_list = []\n",
    "                for i in range(0,5):\n",
    "                    output = model_list[i](data)\n",
    "                    output_list.append(output)\n",
    "                \n",
    "                for j in range(1,5):\n",
    "                    output_list[0]+=output_list[j]\n",
    "                    \n",
    "                loss_eval += self.loss_func(output_list[0], target).item()\n",
    "\n",
    "                pred = output_list[0].argmax(dim=1, keepdim=True)\n",
    "\n",
    "                for itm in pred:\n",
    "                    y_pred.append(int(itm))\n",
    "                for real in target:\n",
    "                    y_true.append(int(real))\n",
    "\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                \n",
    "        baCC = self.print_confusion_matrix(y_pred,y_true)\n",
    "        loss_eval = loss_eval / loader_eval.dataset.__len__()\n",
    "        accuracy = correct / loader_eval.dataset.__len__()\n",
    "        response = {\"loss\": loss_eval, \"acc\": accuracy,\"bACC\":baCC}\n",
    "        return response\n",
    "    \n",
    "    def train(self, loss_func, device):\n",
    "\n",
    "        self.loss_func = loss_func\n",
    "        self.device = device\n",
    "        \n",
    "        accALL = 0\n",
    "        bACCALL = 0\n",
    "        \n",
    "        for i in range(5):\n",
    "            self.model, self.optimizer = init_model()\n",
    "            train_dataset = 0\n",
    "            valid_dataset = 0\n",
    "            record = 0\n",
    "            \n",
    "            for j,dataset0 in zip(range(5),(dataset1, dataset2, dataset3, dataset4, dataset5)):\n",
    "                if j != i:\n",
    "                    if train_dataset == 0:\n",
    "                        train_dataset = dataset0\n",
    "                    else:\n",
    "                        train_dataset += dataset0\n",
    "                else:\n",
    "                    valid_dataset = dataset0\n",
    "            train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "            valid_dataloader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "            train_accs = []\n",
    "            train_losses = []\n",
    "            val_accs = []\n",
    "            val_losses = []\n",
    "            \n",
    "            last_idx = NUM_EPOCHS-1;\n",
    "            \n",
    "            for epoch_idx in range(NUM_EPOCHS):\n",
    "                for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "\n",
    "                    data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                    output = self.model(data)\n",
    "                    loss = loss_func(output, target)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                print(\"Train map\")\n",
    "                train_resp = self.evaluate(self.model, train_dataloader, loss_func)\n",
    "                print(\"Valid map\")\n",
    "                eval_resp = self.evaluate(self.model, valid_dataloader, loss_func)\n",
    "\n",
    "                print(\"-*-*-*-*-*- Epoch {} -*-*-*-*-*-\".format(epoch_idx))\n",
    "                print(\"-*-*-*-*-*- fold {} -*-*-*-*-*-\".format(i))\n",
    "                print(\"Train Loss: {:.6f}\\t\".format(train_resp[\"loss\"]))\n",
    "                print(\"Train Acc: {:.6f}\\t\".format(train_resp[\"acc\"]))\n",
    "                print(\"Train bACC: {:.6f}\\t\".format(train_resp[\"bACC\"]))\n",
    "                print(\"Eval Loss: {:.6f}\\t\".format(eval_resp[\"loss\"]))\n",
    "                print(\"Eval Acc: {:.6f}\\t\".format(eval_resp[\"acc\"]))\n",
    "                print(\"Eval bACC: {:.6f}\\t\".format(eval_resp[\"bACC\"]))\n",
    "                print(\"\\n\")\n",
    "                train_accs.append(train_resp[\"acc\"])\n",
    "                train_losses.append(train_resp[\"loss\"])\n",
    "                val_accs.append(eval_resp[\"acc\"])\n",
    "                val_losses.append(eval_resp[\"loss\"])\n",
    "                if epoch_idx == last_idx:\n",
    "                    accALL += eval_resp[\"acc\"]\n",
    "                    bACCALL += eval_resp[\"bACC\"]\n",
    "                \n",
    "                if epoch_idx > 5:\n",
    "                    if eval_resp[\"acc\"]>record:\n",
    "                        record = eval_resp[\"acc\"]\n",
    "                        torch.save(self.model, \"latest-gp_ai_\"+str(i)+\".pth\")\n",
    "                \n",
    "            show_curve(train_accs, \"train acc\")\n",
    "            show_curve(train_losses, \"train loss\")\n",
    "            show_curve(val_accs, \"val_acc\")\n",
    "            show_curve(val_losses, \"val_loss\")\n",
    "        \n",
    "        print(\"Final avg acc \")\n",
    "        print(accALL/5)\n",
    "        print(\"Final avg bACC\")\n",
    "        print(bACCALL/5)\n",
    "\n",
    "train_player = trainer()\n",
    "train_player.train(loss,DEVICE)\n",
    "train_player.test()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}